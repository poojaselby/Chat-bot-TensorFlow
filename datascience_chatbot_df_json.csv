tag,patterns,responses
greeting,Hi,Hello
greeting,Hey,Hi
greeting,Is anyone there?,Hi there
greeting,Hello,Hello
greeting,Hay,Hey
thanks,Thanks,Happy to help
thanks,Thankyou,Any time
thanks,That’s helpful,My pleasure
thanks,Thanks for helping,You are most welcome
good bye,Bye,See you laterBye
good bye,See you later,Have a nice day!
good bye,GoodBye,Come back again
about,Who are you,I am your Course Bot assistant
about,What are you,I am your Course Bot assistant
about,Who you are,I am your Course Bot assistant
help,Could you help me,Tell me how can I help you
help,give me a hand please,Tell me your problem to assist you
help,Can you help,Yes sure how can I help you
help,I need a help,"Sure, I am here to help you"
data science definition,What is data science,"Data science encompasses a set of principles, problem definitions, algorithms, and processes for extracting nonobvious and useful patterns from large data sets"
data science definition,Define data science,"Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains."
data science definition,data science,"Data science is the study of data. It involves developing methods of recording, storing, and analyzing data to effectively extract useful information. The goal of data science is to gain insights and knowledge from any type of data — both structured and unstructured."
V's of big data,What are V's in Big data,"Volume, Velocity, Variety, Veracity, Value"
V's of big data,5 v’s of big data,"Volume, Velocity, Variety, Veracity, Value"
V's of big data,Big data v’s,"Volume, Velocity, Variety, Veracity, Value"
Volume in big data,Volume in big data ,"The anticipated volume of data that is processed by Big Data solutions is substantial and ever-growing. High data volumes impose distinct data storage and processing demands, as well as additional data preparation, curation and management processes"
Volume in big data,Define volume in big data,"Volume is a huge amount of data.To determine the value of data, size of data plays a very crucial role. If the volume of data is very large then it is actually considered as a ‘Big Data’. This means whether a particular data can actually be considered as a Big Data or not, is dependent upon the volume of data."
Volume in big data,Big data volume,"Volume, the first of the 5 V's of big data, refers to the amount of data that exists. Volume is like the base of big data, as it is the initial size and amount of data that is collected. If the volume of data is large enough, it can be considered big data. What is considered to be big data is relative, though, and will change depending on the available computing power that's on the market."
Volume in big data,Volume,"Volume defines the huge amount of data that is produced each day by companies, for example. The generation of data is so large and complex that it can no longer be saved or analyzed using conventional data processing methods."
Velocity in big Data,Velocity in big data,"In Big Data environments, data can arrive at fast speeds, and enormous datasets can accumulate within very short periods of time. From an enterprise’s point of view, the velocity of data translates into the amount of time it takes for the data to be processed once it enters the enterprise’s perimeter"
Velocity in big Data,Define Velocity in big data,"Velocity refers to the high speed of accumulation of data.In Big Data velocity data flows in from sources like machines, networks, social media, mobile phones etc.There is a massive and continuous flow of data. This determines the potential of data that how fast the data is generated and processed to meet the demands.Sampling data can help in dealing with the issue like ‘velocity’.
"
Velocity in big Data, Big data velocity,"Velocity refers to how quickly data is generated and how quickly that data moves. This is an important aspect for companies need that need their data to flow quickly, so it's available at the right times to make the best business decisions possible."
Veracity in big Data,Veracity in big data,"Veracity refers to the quality or fidelity of data. Data that enters Big Data environments needs to be assessed for quality, which can lead to data processing activities to resolve invalid data and remove noise"
Veracity in big Data, Define Veracity in big data,"Veracity refers to the quality and accuracy of data. Gathered data could have missing pieces, may be inaccurate or may not be able to provide real, valuable insight. Veracity, overall, refers to the level of trust there is in the collected data."
Veracity in big Data,Big data Veracity,"Veracity refers to inconsistencies and uncertainty in data, that is data which is available can sometimes get messy and quality and accuracy are difficult to control. Big Data is also variable because of the multitude of data dimensions resulting from multiple disparate data types and sources.
"
Value,Value in big data,"Value is defined as the usefulness of data for an enterprise. The value characteristic is intuitively related to the veracity characteristic in that the higher the data fidelity, the more value it holds for the business"
Value, Define Value in big data,"It is the value of data that big data can provide, and it relates directly to what organizations can do with that collected data. Being able to pull value from big data is a requirement, as the value of big data increases significantly depending on the insights that can be gained from them."
Value,Big data Value,"
Value in big data  refers to the usefulness of gathered data for your business"
DIKW Pyramid,What id DIKW Pyramid,"It is a standard model of structural relationship between wisdom, knowledge, information and data."
DIKW Pyramid,DIKW Pyramid,"The DIKW Pyramid represents the relationships between data, information, knowledge and wisdom. Each building block is a step towards a higher level - first comes data, then is information, next is knowledge and finally comes wisdom."
DIKW Pyramid,Define DIKW pyramid,"The Data, Information, Knowledge, Wisdom (DIKW) framework is one of the core conceptual frameworks for the practice of nursing informatics."
Data in DIKW Pyramid,what is data in DIKW Pyramid,Data is created through abstractions or measurements taken from the world. These are the facts and statistics collected together for reference or analysis
Data in DIKW Pyramid,Data in DIKW Pyramid,Data is created through abstractions or measurements taken from the world. These are the facts and statistics collected together for reference or analysis
Data in DIKW Pyramid,D in DIKW Pyramid,Data is created through abstractions or measurements taken from the world. These are the facts and statistics collected together for reference or analysis
Information in DIKW Pyramid,What is Information in DIKW Pyramid,"Information is data that have been processed, structured or contextualized so that It is meaningful to humans""]"
Information in DIKW Pyramid,Information in DIKW Pyramid,"Information is Meaningful, purposeful, and relevant data  which is understandable to humans. It will answer interrogative questions."
Information in DIKW Pyramid,I in DIKW Pyramid,"Information is the next building block of the DIKW Pyramid. This is data that has been “cleaned” of errors and further processed in a way that makes it easier to measure, visualize and analyze for a specific purpose."
Knowledge in DIKW Pyramid,What is Knowledge in DIKW Pyramid,Knowledge is information that has been interpreted and understood by a human so that he/she can act on it if required.
Knowledge in DIKW Pyramid,Knowledge in DIKW Pyramid,Knowledge is information that has been interpreted and understood by a human so that he/she can act on it if required.
Knowledge in DIKW Pyramid,K in DIKW Pyramid,Knowledge is information that has been interpreted and understood by a human so that he/she can act on it if required.
Wisdom in DIKW Pyramid,What is Wisdom in DIKW Pyramid,"It is a process to get the final result by calculating through extrapolation ok knowledge. It considers the output from all the previous levels of DIKW Model and processes them through special types of human programming(moral, ethical codes etc"
Wisdom in DIKW Pyramid,Wisdom in DIKW Pyramid,"Wisdom is the top of the DIKW hierarchy and to get there, we must answer questions such as ‘why do something’ and ‘what is best’. In other words, wisdom is knowledge applied in action."
Wisdom in DIKW Pyramid,W in DIKW Pyramid,"It is a process to get the final result by calculating through extrapolation ok knowledge. It considers the output from all the previous levels of DIKW Model and processes them through special types of human programming(moral, ethical codes etc"
Data science applications,What are the applications of data science,"Banking and Financial Sector ,HealthCare , Social Media ,Travel and Tourism , Agriculture, Marketing and Sales"
Data science applications,List the applications in data science,"Some of the applications of Data Science are : Fraud and Risk Detection, Healthcare, Marketing, Travel and Tourism, Agriculture, Banking etc."
Data science applications,Applications of data science,"Top applications of datascience are: Fraud and Risk Detection, Healthcare, Marketing, Banking, Travel and Tourism"
Banking and Financial Sector uses cases data science,Use cases of banking and financial sector in data science,"The usecases of datascinece in banking are:  Fraud and Risk detection, Claim prediction ,Risk Estimation , Personalized Marketing"
Banking and Financial Sector uses cases data science,Data science uses in banking and financial sector,"Applications  using data scinece can help financial firms incorporate data into every decision they make; they can automate data mining and predictive modelling for daily use and weave advanced statistical analysis, machine learning, and Artificial Intelligence into the Bank's day-to-day operations."
Banking and Financial Sector uses cases data science,what are the use cases of banking and financial sector using data science,"Using data science in the banking industry is more than a trend, it has become a necessity to keep up with the competition. Banks have to realize that big data technologies can help them focus their resources efficiently, make smarter decisions, and improve performance. Through data science bank can efficiently manage fraud and risk detection, customer segmentation, loan approval, credit scoring etc."
Health care uses cases data science,Use cases of health care sector in data science,"Optimized and integrated care, Image analysis and problem detection, communication assistance, medication effectiveness, personalized medicine"
Health care uses cases data science,Data science uses in health care sector,"Data science plays a vital role to obtain accurate diagnostic measures so that human prone errors can be mitigated. Machine learning algorithms can be used to create complete comprehensive health reports which can be used in future to calculate critical insights to provide a better treatment to patients. Data science can be used in the following areas of healthcare: Diagnostic accuracy,  Visual data processing for tumour detection, Accelerating Medical research
Finding the best cure etc. "
Health care uses cases data science,what are the use cases of health care using data science,"Data Science helps in the recognition of scanned images to figure out the defects in a human body for helping doctors make an effective treatment strategy. These medical image tests include X-ray, sonography, MRI (Magnetic Resonance Imaging), CT scan, and many more."
Social media uses cases  data science,Use cases of social media sector in data science,"Uses cases of data science in social media sector are : Sentimental analysis, User segmentation, Image recognition, Digital marketing and many more."
Social media uses cases  data science,Data science uses in social media sector,"Social media analytics and big data analytics are used to support marketing strategies, including measuring marketing performance KPIs, monitoring the effectiveness of campaigns, and creating contextualized, personalized ads and content based on customer sentiment."
Social media uses cases  data science,what are the use cases of social media using data science,"Social media platforms create a continuous flow of data that might be hard to store and analyse because most of the data are unstructured. Data science can be effectively used to analyse the data and to strengthen the user-experience as well as to deliver personalized contents in social media. Data scinece can help to monitor the social media, text and image recognition, content recommendation, Neural translation etc."
Travel uses cases data science,Use cases for travel sector in data science,"Some of the uses cases of Data Science in travel sector are: Dynamic pricing, Customer Segmentation, Personalized marketing, Flight delay prediction, Route optimization, Digital marketing"
Travel uses cases data science,Data science uses in travel and tourism sector,"Travel and tourism is the fastest growing sector because people travel a lot now a days and travel booking is one of the area that is highly automated with algorithms. This travel boom was achieved with the help of technology and data science. Data science can help travel and toursim sector in many ways such as: Personalised marketing  and customer segmentation , Customer sentimental analysis, Recommendation engines, Travel support bots, Anaytics and many more."
Travel uses cases data science,what are the use cases of travel and tourism using data science,"Some of the application scenarios for machine learning and data analytics in the travel industry are :Forecasting hotel and flight price,  Intelligent travel assistants,Recommendation Engine,Sentimental analysis in social media etc. "
Marketing and sales uses cases data science,Use cases for marketing and sales sector in data science,"Some of the use cases of Data Science in Marketing and Sales sector is: Customer Segmentation, Demand Forecasting, Tracking customer behaviour, Personalized  marketing, Upselling and Cross selling, Discount Offering"
Marketing and sales uses cases data science,Data science uses in marketing and sales sector,"Marketing is an important strategy to ensure the growth of business and through marketing only, money which is the goal of a business can be achieved. Data science is used to enhance various factors in marketing and sales sector which are: Predicting sales, Better cross selling and up selling, Market-Basket Analysis, Pricing Strategy etc."
Marketing and sales uses cases data science,what are the use cases of marketing and sales using data science,"Data has now become the building blocks across all industries and is vital for sales leaders to run their operations effectively, focus on viable strategies, generate leads, enhance customer experience and uncover hidden opportunities. The major use case of data science in sales are: Predicting sales, Improve lead generation,analyzing customer sentiment, better cross-selling and up-selling, improving CLV, Setting the right price."
CRISP - DM,What is CRISP - DM,"The Cross Industry Standard Process for Data Mining (CRISP-DM) is a process model with six phases that naturally describes the data science life cycle. It's like a set of guardrails to help you plan, organize, and implement your data science (or machine learning) project."
CRISP - DM, Explain CRISP - DM,"CRISP-DM is a process made up of six different phases. These include Business Understanding, Data Understanding, Data Preparation, Modeling, Evaluation and Deployment."
CRISP - DM,Full form of CRISP -DM,"The full of CRISP-DM is  Cross-Industry Standard Process for Data Mining. CRISP-DM encourages best practices and allows projects to replicate. This methodology provides a uniform framework for planning and managing a project. Being cross-industry standard, CRISP-DM can be implemented in any Data Science project irrespective of its domain."
CRISP-DM life cycle,What are the steps in CRISP-DM life cycle,"The steps in CRISP-DM model is: Busines understanding, Data understanding, Data preperation, Modeling,Evalutaion and Deployment"
CRISP-DM life cycle,Steps in CRISP-DM process,"The steps in CRISP-DM model is: Busines understanding, Data understanding, Data preperation, Modeling,Evalutaion and Deployment"
CRISP-DM life cycle,Stages of CRISP-DM,"The steps in CRISP-DM model is: Busines understanding, Data understanding, Data preperation, Modeling,Evalutaion and Deployment"
CRISP-DM life cycle,CRISP-DM life cycle,"There are six stages in CRISP-DM model and they are: Busines understanding, Data understanding, Data preperation, Modeling,Evalutaion and Deployment"
Data science ecosystem,What is a data science ecosystem ,"A collection of infrastructure, analytics, and applications used to capture and analyze data. It provide companies with data that they rely on to understand their customers and to make better pricing, operations, and marketing decisions. Data ecosystems are intended to evolve over time"
Data science ecosystem,Data science ecosystem,"The term data ecosystem refers to the programming languages, packages, algorithms, cloud-computing services, and general infrastructure an organization uses to collect, store, analyze, and leverage data."
Data science ecosystem,Explain data science ecosystem ,"The term data ecosystem refers to the programming languages, packages, algorithms, cloud-computing services, and general infrastructure an organization uses to collect, store, analyze, and leverage data."
Types of data,Which are the types of data,"There are two types of data. Numerical and Categorical. Categorical can be classified as Ordinary, Binary, Nominal and Numerical can be classified as Discrete and Continuous"
Types of data,Types of data,"Data can be classified into two : Numerical and Categorical where numeical can be classified as discrete and continous and numerical can be classified as ordinary,binary and nominal."
Types of data,List the types of data,"Types of data are: Numerical and Categorical  where numeical can be classified as discrete and continous and numerical can be classified as ordinary,binary and nominal."
Numerical data,Define numerical data type,Numerical data is information that is measurable and  represented as numbers. It can be Discreate or Continuous
Numerical data,what is a numerical data type,"Numerical data can take 2 different forms, namely; discrete data, which represents countable items and continuous data, which represents data measurement."
Numerical data,Numerical data type,The types of data that can be repreneted in numbers are called numerical data and is classified into continous and discrete.
Discrete data,Define discrete data type,Discrete data is information that can only take certain values. These values don’t have to be whole numbers (a child might have a shoe size of 3.5 or a company may make a profit of £3456.25 for example) but they are fixed values – a child cannot have a shoe size of 3.72!
Discrete data,what is a discrete data type,"Discrete data is information that can only take certain values. This type of data is often represented using tally charts, bar charts or pie charts. "
Discrete data,Discrete data type,"Discrete Data can only take certain values.Discrete data is data such as occurrences, proportions, or characteristics (for example, pass or fail) and is counted (for example, the number or proportion of people waiting in a queue, or the number of defective items in a sample). Discrete data is counted in non-negative integers (1, 2, 3, etc.)."
Continuous data,Define continuous data type,"Continuous data is data that can take any value. Height, weight, temperature and length are all examples of continuous data. Some continuous data will change over time; the weight of a baby in its first year or the temperature in a room throughout the day. "
Continuous data,what is a continuous data type,"Continuous data is data that can be measured on an infinite scale, It can take any value between two numbers, no matter how small. The measure can be virtually any value on the scale. Measures of time, height, temperature, and thickness are all examples of continuous data."
Continuous data,Continuous data type,"Continuous data is data that can be measured on an infinite scale, It can take any value between two numbers, no matter how small. The measure can be virtually any value on the scale. "
Categorical data,Define categorical data type,"Categorical data is any data that isn’t number; which can mean a string of text or date. It can be mainly Ordinal, or Nominal"
Categorical data,what is a categorical data type,"A categorical variable is a variable that can take on one of a limited, and usually fixed, number of possible values, assigning each individual or other unit of observation to a particular group or nominal category on the basis of some qualitative property."
Categorical data,Categorical data type,"Categorical data is a collection of information that is divided into groups. I.e, if an organisation or agency is trying to get a biodata of its employees, the resulting data is referred to as categorical. This data is called categorical because it may be grouped according to the variables present in the biodata such as sex, state of residence, etc."
Ordinal data,Define ordinal data type,"Ordinal data is a statistical type of quantitative data in which variables exist in naturally occurring ordered categories. ... In statistics, a group of ordinal numbers indicates ordinal data and a group of ordinal data are represented using an ordinal scale."
Ordinal data,what is a ordinal data type,Ordinal data are the type of data in which the values follow a natural order. One of the most notable features of ordinal data is that the differences between the data values cannot be determined or are meaningless.
Ordinal data,Ordinal data type,"Ordinal data is a categorical, statistical data type where the variables have natural, ordered categories and the distances between the categories is not known. "
Nominal data,Define nominal data type,"Nominal data represent values with no set order to them. Examples, Variables such as Country or Marital Status"
Nominal data,what is a nominal data type,Nominal data (also known as nominal scale) is a type of data that is used to label variables without providing any quantitative value. It is the simplest form of a scale of measure.
Nominal data,Nominal data type,"Nominal scale is a naming scale, where variables are simply “named” or labeled, with no specific order.Examples of nominal data include country, gender, race, hair color etc. of a group of people."
Binary data,Define binary data type,"Binary data a special type of categorical data type having only two values – yes or no. This can be represented in different ways such as True and False or 1 and 0. Often used to represent one of two conceptually opposed values, e.g: the outcome of an experiment (success or failure"
Binary data,what is a binary data type,Binary data is a type of data that is represented or displayed in the binary numeral system. Binary data is the only category of data that can be directly understood and executed by a computer. It is numerically represented by a combination of zeros and ones
Binary data,Binary data type,"Binary data is data whose unit can take on only two possible states, traditionally labeled as 0 and 1 in accordance with the binary numeral system and Boolean algebra."
Big data,what is big data,"Big data refers to extremely large data sets that may be analyzed computationally to reveal patterns, trends, and associations, especially relating to human behavior and interactions. It is larger, more complex data sets, especially from new data sources"
Big data,define big data,"Big data is a field that treats ways to analyze, systematically extract information from, or otherwise deal with data sets that are too large or complex to be dealt with by traditional data-processing application software."
Big data,explain big data,"Big data is a term applied to data sets whose size or type is beyond the ability of traditional relational databases to capture, manage and process the data with low latency. Big data has one or more of the following characteristics: high volume, high velocity or high variety. "
Big data challenges,Challenges in big data,"Top six challenges of Big Data are: Lack of proper understanding of data, Data growing issues, Lack of data professionals,Data security,Integration of data, Big data tool selection"
Big data challenges,Mention big data challeneges,"There are many challenges in working with big data, some of them are:  Lack of proper understanding of data, Data growing issues, Lack of data professionals,Data security,Integration of data, Big data tool selection,Data Security,Data Capture etc."
Big data challenges,What are the challenges for big data,"The main challenges of big data are: Data Integration, Data Complexity, Data Security,Data Capture, Data Scaling, Data Mobility, Data Value etc."
data,Explain data,"Data are raw, unorganized facts gathered about someone or something, usually simple and random. Data are records and observation that need to be processed"
data,Define data,"Data is defined as facts or figures, or information that's stored in or used by a computer. An example of data is information collected for a research paper. An example of data is an email. ... Statistics or other information represented in a form suitable for processing by computer."
data,What is data,"Data are individual facts, statistics, or items of information, often numeric, that are collected through observation. In a more technical sense, data are a set of values of qualitative or quantitative variables about one or more persons or objects."
structured data,Explain structured data,"Data that can be stored in a tabular form is called structured data. Structured data can be easily stored, organized, searched, recorded, and merged with other structured data. Example: The demographic data for a population where each row in the table describes one person (attributes: name, age, date of birth, gender, address, education, employment status etc.) "
structured data,Define structured data,"The term structured data refers to data that resides in a fixed field within a file or record. Structured data is typically stored in a relational database (RDBMS). It can consist of numbers and text, and sourcing can happen automatically or manually, as long as it's within an RDBMS structure."
structured data,What is structured data,"Semi-structured data is a form of structured data that does not obey the tabular structure of data models associated with relational databases or other forms of data tables, but nonetheless contains tags or other markers to separate semantic elements and enforce hierarchies of records and fields within the data."
Unstructured data,Unstructured data,Data that is not necessarily in the same in every instance and each instance might have its own internal structure. Example: Dataset of webpages; each website might have data of a unique type.
Unstructured data,Explain unstructured data,Unstructured simply means that it is datasets (typical large collections of files) that aren't stored in a structured database format.
Unstructured data,Define unstructured data,"Unstructured data is information that either does not have a pre-defined data model or is not organized in a pre-defined manner. Unstructured information is typically text-heavy, but may contain data such as dates, numbers, and facts as well."
Unstructured data,What is unstructured data," Unstructured simply means that it is datasets (typical large collections of files) that aren’t stored in a structured database format. Unstructured data has an internal structure, but it’s not predefined through data models. It’s so prolific because unstructured data could be anything: media, imaging, audio, sensor data, text data, and much more."
Missing value,Missing value,"A variable in an observation does not have any value recorded. Common in most real-world datasets (examples: incomplete or partial data for an observation, missing sequence, incomplete feature, reporting error etc.)"
Missing value,Explain missing value,"Missing data, or missing values, occur when no data value is stored for the variable in an observation. Missing data are a common occurrence and can have a significant effect on the conclusions that can be drawn from the data. "
Missing value,Define missing value,Missing data are values that are not recorded in a dataset. They can be a single value missing in a single cell or missing of an entire observation (row). Missing data can occur both in a continuous variable (e.g. height of students) or a categorical variable (e.g. gender of a population).
Missing value,What is  a missing value,Missing data are values that are not recorded in a dataset. They can be a single value missing in a single cell or missing of an entire observation (row). Missing data can occur both in a continuous variable (e.g. height of students) or a categorical variable (e.g. gender of a population).
Missing value types,Types of missing value,Missing values can be divided as: MCAR: Missing completely at random where missing values are randomly distributed. MAR:  Missing at random where missing values are distributed within one or more sub-samples.
Missing value types,Explain the types of missing value,"There are four types of missing data that are generally categorized. Missing completely at random (MCAR), missing at random, missing not at random, and structurally missing. Each type may be occurring in your data or even a combination of multiple missing data types"
Missing value types,What are the types of missing values,"There are four qualitatively distinct types of missing data. Missing data is either: structurally missing, missing completely at random (MCAR), missing at random, or nonignorable (also known as missing not at random). Different types of missing data need to be treated differently in order for any analysis to be meaningful."
Handling missing values,Approaches to handle missing values,Missing data can be handled using three approaches:1. Imputation 2. Omission 3. Analysis
Handling missing values,handling missing values,"Best techniques to handle missing data are: Use deletion methods to eliminate missing data, Use regression analysis to systematically eliminate data,Data scientists can use data imputation techniques"
Handling missing values,techniques to handle missing values,"Techniques used to handle missing data are: Deleting Rows with missing values, Impute missing values for continuous variable.Impute missing values for categorical variable, Other Imputation Methods, Using Algorithms that support missing values, Prediction of missing values."
Handling missing values,how to handle missing data,"Techniques used to handle missing data are: Deleting Rows with missing values, Impute missing values for continuous variable.Impute missing values for categorical variable, Other Imputation Methods, Using Algorithms that support missing values, Prediction of missing values."
Imputation,Imputation to handle missing values,In imputation values are filled in the place of missing data and it works well for situation where analysis tools are not robust to missing values . Dataset sizes are not reduced but noise gets imposed with the imputation
Imputation,what is imputation, Imputation is a technique used for replacing the missing data with some substitute value to retain most of the data/information of the dataset.
Imputation,How imputation is used to handle missing values,"imputation is the process of replacing missing data with substituted values. When substituting for a data point, it is known as ""unit imputation""; when substituting for a component of a data point, it is known as ""item imputation""."
Exploratory data analysis,What is EDA?,"An approach to explore the data set with the tables, charts, and other visualization tools. Helps to formulate hypothesis and guide data preparation process.Examples of EDA are: Line chart, Bar chart, Pie chart etc."
Exploratory data analysis,Explain exploratory data analysis,"Exploratory data analysis is an approach of analyzing data sets to summarize their main characteristics, often using statistical graphics and other data visualization methods."
Exploratory data analysis,What is exploratory data analysis,"Exploratory Data Analysis refers to the critical process of performing initial investigations on data so as to discover patterns,to spot anomalies,to test hypothesis and to check assumptions with the help of summary statistics and graphical representations."
Feature Extraction in data,What is feature extraction?,Feature extraction is a process of dimensionality reduction by which an initial set of raw data is reduced to more manageable groups for processing. A characteristic of these large data sets is a large number of variables that require a lot of computing resources to process.
Feature Extraction in data,Explain feature extraction,The feature Extraction technique gives us new features which are a linear combination of the existing features. The new set of features will have different values as compared to the original feature values. The main aim is that fewer features will be required to capture the same information
Feature Extraction in data,Feature extraction,Feature selection is an important approach for reducing the dimension of high-dimensional data . It is an important approach for reducing the dimension of high-dimensional data.
Outliers in data,Outliers in data,An outlier is a data point that differs significantly from other observations. An outlier may be due to variability in the measurement or it may indicate experimental error; the latter are sometimes excluded from the data set. An outlier can cause serious problems in statistical analyses.
Outliers in data,What are outliers?,"An outlier is a piece of data that is an abnormal distance from other points. In other words, it’s data that lies outside the other values in the set. If you had Pinocchio in a class of children, the length of his nose compared to the other children would be an outlier."
Outliers in data,Explain Outlier,An outlier is an observation that lies an abnormal distance from other values in a random sample from a population. Examination of the data for unusual observations that are far removed from the mass of data. These points are often referred to as outliers.
Noise in data,Noise in data,Noisy data are data with a large amount of additional meaningless information in it called noise. This includes data corruption and the term is often used as a synonym for corrupt data. Noisy data can adversely affect the results of any data analysis and skew conclusions if not handled properly.
Noise in data,What is a noise in data,"Noisy data are data that is corrupted, or distorted, or has a low Signal-to-Noise Ratio. Improper procedures to subtract out the noise in data can lead to a false sense of accuracy or false conclusions"
Noise in data,Explain noise in data,"Noisy data is meaningless data. Any data that has been received, stored, or changed in such a manner that it cannot be read or used by the program that originally created it can be described as noisy. Noisy data unnecessarily increases the amount of storage space required and can also adversely affect the results of any data mining analysis."
Data Pre-processing,What is data preprocessing?,"Data preprocessing is a data mining technique that involves transforming raw data into an understandable format. Real-world data is often incomplete, inconsistent, and/or lacking in certain behaviors or trends, and is likely to contain many errors. Data preprocessing is a proven method of resolving such issues."
Data Pre-processing,Explain data preprocessing,Data preprocessing is a data mining technique which is used to transform the raw data in a useful and efficient format. 
Data Pre-processing,Data preprocessing,"Data preprocessing is a process of preparing the raw data and making it suitable for a machine learning model. It is the first and crucial step while creating a machine learning model.When creating a machine learning project, it is not always a case that we come across the clean and formatted data. And while doing any operation with data, it is mandatory to clean it and put in a formatted way. So for this, we use data preprocessing task.
"
Dimensionality reduction,What is dimensionality reduction,"Dimensionality reduction refers to techniques for reducing the number of input variables in training data. Fewer input dimensions often mean correspondingly fewer parameters or a simpler structure in the machine learning model, referred to as degrees of freedom."
Dimensionality reduction,Explain dimensionality reduction,"Dimensionality reduction, or dimension reduction, is the transformation of data from a high-dimensional space into a low-dimensional space so that the low-dimensional representation retains some meaningful properties of the original data, ideally close to its intrinsic dimension."
Dimensionality reduction,Dimensionality reduction,"Dimensionality reduction is a series of techniques in machine learning and statistics to reduce the number of random variables to consider. It involves feature selection and feature extraction. Dimensionality reduction makes analyzing data much easier and faster for machine learning algorithms without extraneous variables to process, making machine learning algorithms faster and simpler in turn."
Supervised Learning ,What is supervised learning algorithms,"Supervised learning is the types of machine learning in which machines are trained using well ""labelled"" training data, and on basis of that data, machines predict the output. ... Supervised learning is a process of providing input data as well as correct output data to the machine learning model."
Supervised Learning ,Explain supervised learning algorithms,Supervised learning is the machine learning task of learning a function that maps an input to an output based on example input-output pairs. It infers a function from labeled training data consisting of a set of training examples. 
Supervised Learning ,Supervised learning algorithms,"Supervised learning uses a training set to teach models to yield the desired output. This training dataset includes inputs and correct outputs, which allow the model to learn over time. The algorithm measures its accuracy through the loss function, adjusting until the error has been sufficiently minimized."
Unsupervised Learning,What is unsupervised learning algorithms,"Unsupervised learning refers to the use of artificial intelligence (AI) algorithms to identify patterns in data sets containing data points that are neither classified nor labeled. In other words, unsupervised learning allows the system to identify patterns within data sets on its own."
Unsupervised Learning,Explain unsupervised learning algorithms,Unsupervised learning is a type of machine learning in which models are trained using unlabeled dataset and are allowed to act on that data without any supervision.
Unsupervised Learning,Unsupervised learning algorithms,"Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets. These algorithms discover hidden patterns or data groupings without the need for human intervention."
Measures of central tendency,What is measures of central tendency,"A measure of central tendency (also referred to as measures of centre or central location) is a summary measure that attempts to describe a whole set of data with a single value that represents the middle or centre of its distribution. There are three main measures of central tendency: the mode, the median and the mean."
Measures of central tendency,Explain measures of central tendency,"A measure of central tendency is a summary statistic that represents the center point or typical value of a dataset. These measures indicate where most values in a distribution fall and are also referred to as the central location of a distribution.The three most common measures of central tendency are the mean, median, and mode."
Measures of central tendency,measures of central tendency,"A measure of central tendency is a summary statistic that represents the center point or typical value of a dataset. These measures indicate where most values in a distribution fall and are also referred to as the central location of a distribution.The three most common measures of central tendency are the mean, median, and mode."
